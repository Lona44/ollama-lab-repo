# ğŸ§ª Ollama LLM Lab (Docker + Flask)

This project is a lightweight local LLM lab that connects a simple Flask API to a locally running [Ollama](https://ollama.com/) server (e.g. using Mistral). It lets you send prompts to a local LLM using Docker, with minimal setup.

---

## ğŸ—ï¸ Project Structure

```
ollama-llm-lab/
â”‚
â”œâ”€â”€ llm-app/
â”‚   â”œâ”€â”€ app.py              # Flask API code
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ Dockerfile          # Flask container image
â”‚
â”œâ”€â”€ docker-compose.yml      # Spins up the Flask API
â””â”€â”€ README.md               # You're reading it
```

---

## ğŸš€ Prerequisites

- [Docker Desktop](https://www.docker.com/products/docker-desktop/)
- [Ollama](https://ollama.com/) installed locally  
  *(run `ollama serve` to start the server)*

---

## ğŸ§ª Quickstart (Test Locally First)

1. **Start Ollama:**

   In a dedicated terminal:
   ```bash
   ollama serve
   ```

2. **Pull your model (e.g. Mistral):**

   Only needs to be done once:
   ```bash
   ollama pull mistral
   ```

3. **Start the Flask API via Docker Compose:**

   In your project folder:
   ```bash
   docker compose up --build
   ```

4. **Test the endpoint:**

   In a new terminal:
   ```bash
   curl -X POST http://localhost:5050/chat \
     -H "Content-Type: application/json" \
     -d '{"message": "What is 2 + 2?"}'
   ```

   âœ… You should get a valid LLM response like:
   ```json
   {"message":{"role":"assistant","content":"2 + 2 equals 4."}, ...}
   ```

---

## ğŸ” How It Works

- Flask handles `/chat` requests.
- It sends your message to `http://host.docker.internal:11434/api/chat`.
- Ollama processes it using the `mistral` model.
- Flask returns the LLM's response to you.

---

## ğŸ›‘ To Stop Everything

```bash
docker compose down
```

To clean everything:
```bash
docker system prune -a
```

---

## ğŸ¤– Example Payload

```bash
curl -X POST http://localhost:5050/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Tell me a joke"}'
```

---
